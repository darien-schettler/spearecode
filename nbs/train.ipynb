{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0acb0112-c7aa-4f44-b9f2-b00adce49d8e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<b>Imports and Constants</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d4bf6c3-8590-4e25-95f7-24a62edd1c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q --upgrade tokenizer-viz\n",
    "\n",
    "# Regular imports (native python and pypi packages)\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import sentencepiece as spm\n",
    "from IPython.display import HTML, display\n",
    "from tokenizer_viz import TokenVisualization\n",
    "from tqdm.notebook import tqdm; tqdm.pandas()\n",
    "\n",
    "# Add project root into path so imports work\n",
    "PROJECT_DIR = os.path.dirname(os.getcwd())\n",
    "sys.path.insert(0, PROJECT_DIR) \n",
    "\n",
    "# Our project imports\n",
    "from spearecode.utils.preprocessing_utils import (\n",
    "    load_from_txt_file, preprocess_shakespeare, save_to_txt_file, print_check_speare, get_spm_assets\n",
    ")\n",
    "from spearecode.utils.general_utils import (\n",
    "    tf_xla_jit, tf_set_memory_growth, seed_it_all, flatten_l_o_l, print_ln\n",
    ")\n",
    "from spearecode.utils.filtering_utils import (\n",
    "    save_ds_version, drop_str_from_col_names, pad_truncate_centered,\n",
    "    get_metadata_df, check_chunks, tokenize, get_n_tokens,\n",
    "    get_n_lines, get_n_chars\n",
    ")\n",
    "from spearecode.utils.tfrecord_utils import write_tfrecords, load_tfrecord_dataset\n",
    "\n",
    "TRAIN_STYLE = \"rcts_bpe_v4\"\n",
    "CHUNK_STYLE, TOK_STYLE, DS_VERSION = TRAIN_STYLE.split(\"_\")\n",
    "\n",
    "### DEFINE PATHS --- [PROJECT_DIR=\"/home/paperspace/home/spearecode\"] --- ###\n",
    "NBS_PATH = os.path.join(PROJECT_DIR, \"nbs\")\n",
    "DATA_PATH = os.path.join(PROJECT_DIR, \"data\")\n",
    "SS_TEXT_PATH = os.path.join(DATA_PATH, \"t8.shakespeare.txt\")\n",
    "PREPROCESSED_FULL_TEXT_PATH = SS_TEXT_PATH.replace(\".txt\", \"_preprocessed.txt\")\n",
    "\n",
    "DATASETS_PATH = os.path.join(DATA_PATH, \"datasets\") \n",
    "META_DIR = os.path.join(DATASETS_PATH, \"meta\") \n",
    "TFRECORD_DIR = os.path.join(DATASETS_PATH, \"tfrecords\", TRAIN_STYLE)\n",
    "MODELS_DIR = os.path.join(PROJECT_DIR, \"models\")\n",
    "\n",
    "# Specific Paths\n",
    "SPM_MODEL_PATH = os.path.join(MODELS_DIR, f\"spearecode_{TOK_STYLE}\")\n",
    "DATA_CSV_PATH  = os.path.join(DATASETS_PATH, f\"{DS_VERSION}_{CHUNK_STYLE}_{TOK_STYLE}.csv\")\n",
    "META_CSV_PATH  = os.path.join(META_DIR, f\"{DS_VERSION}_{CHUNK_STYLE}_{TOK_STYLE}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2accc846-874c-4bfc-9bef-b01ca883f5a1",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<b>Instantiate expected tools for the reset of the notebook</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2dec0a8-a181-492a-ac75-f397776c522c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>token_content</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>n_lines</th>\n",
       "      <th>valid_chunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1\\n  From fairest creatures we desire increase...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>192</td>\n",
       "      <td>643</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2\\n  When forty winters shall besiege thy brow...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>188</td>\n",
       "      <td>662</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3\\n  Look in thy glass and tell the face thou ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>183</td>\n",
       "      <td>643</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4\\n  Unthrifty loveliness why dost thou spend,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>183</td>\n",
       "      <td>619</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5\\n  Those hours that with gentle work did fra...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>176</td>\n",
       "      <td>652</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7694</th>\n",
       "      <td>'\"Lo, this device was sent me from a nun,\\n  O...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>282</td>\n",
       "      <td>944</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7695</th>\n",
       "      <td>'\"How mighty then you are, O hear me tell!\\n  ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>298</td>\n",
       "      <td>983</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7696</th>\n",
       "      <td>'\"Now all these hearts that do on mine depend,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>283</td>\n",
       "      <td>977</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7697</th>\n",
       "      <td>'For lo, his passion, but an art of craft,\\n  ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>292</td>\n",
       "      <td>965</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7698</th>\n",
       "      <td>'Thus merely with the garment of a Grace  \\n  ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>199</td>\n",
       "      <td>630</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7699 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  \\\n",
       "0     1\\n  From fairest creatures we desire increase...   \n",
       "1     2\\n  When forty winters shall besiege thy brow...   \n",
       "2     3\\n  Look in thy glass and tell the face thou ...   \n",
       "3     4\\n  Unthrifty loveliness why dost thou spend,...   \n",
       "4     5\\n  Those hours that with gentle work did fra...   \n",
       "...                                                 ...   \n",
       "7694  '\"Lo, this device was sent me from a nun,\\n  O...   \n",
       "7695  '\"How mighty then you are, O hear me tell!\\n  ...   \n",
       "7696  '\"Now all these hearts that do on mine depend,...   \n",
       "7697  'For lo, his passion, but an art of craft,\\n  ...   \n",
       "7698  'Thus merely with the garment of a Grace  \\n  ...   \n",
       "\n",
       "                                          token_content  n_tokens  n_chars  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       192      643   \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       188      662   \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       183      643   \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       183      619   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       176      652   \n",
       "...                                                 ...       ...      ...   \n",
       "7694  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       282      944   \n",
       "7695  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       298      983   \n",
       "7696  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       283      977   \n",
       "7697  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       292      965   \n",
       "7698  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       199      630   \n",
       "\n",
       "      n_lines  valid_chunk  \n",
       "0          15         True  \n",
       "1          15         True  \n",
       "2          15         True  \n",
       "3          15         True  \n",
       "4          15         True  \n",
       "...       ...          ...  \n",
       "7694       23         True  \n",
       "7695       23         True  \n",
       "7696       23         True  \n",
       "7697       23         True  \n",
       "7698       15         True  \n",
       "\n",
       "[7699 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>n_lines</th>\n",
       "      <th>valid_chunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192</td>\n",
       "      <td>643</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>662</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>183</td>\n",
       "      <td>643</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>183</td>\n",
       "      <td>619</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>176</td>\n",
       "      <td>652</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7694</th>\n",
       "      <td>282</td>\n",
       "      <td>944</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7695</th>\n",
       "      <td>298</td>\n",
       "      <td>983</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7696</th>\n",
       "      <td>283</td>\n",
       "      <td>977</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7697</th>\n",
       "      <td>292</td>\n",
       "      <td>965</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7698</th>\n",
       "      <td>199</td>\n",
       "      <td>630</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7699 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      n_tokens  n_chars  n_lines  valid_chunk\n",
       "0          192      643       15         True\n",
       "1          188      662       15         True\n",
       "2          183      643       15         True\n",
       "3          183      619       15         True\n",
       "4          176      652       15         True\n",
       "...        ...      ...      ...          ...\n",
       "7694       282      944       23         True\n",
       "7695       298      983       23         True\n",
       "7696       283      977       23         True\n",
       "7697       292      965       23         True\n",
       "7698       199      630       15         True\n",
       "\n",
       "[7699 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>span.token {font-family: Courier New; font-size: 1.1em; font-weight: 300; padding: 0px; margin-right: 0px; border-color: rgba(0, 0, 0, 0.05); border-style: ridge; border-radius: 0px;}</style><div style='background-color: #FBFBFB; line-height: 175%; padding: 25px; border-radius: 8px; margin-left: 10px; margin-right: 10px; margin-top: 20px; margin-bottom: 20px; overflow-x: auto; white-space: nowrap;'><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>Prince</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>.</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;Re</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>bell</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>ious</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;subjects</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>,</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;enemies</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;to</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;peace</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>,</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>Pro</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>f</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>an</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>ers</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;of</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;this</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;neighbour</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>-</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>stain</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>ed</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;steel</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>-</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>Will</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;they</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;not</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;hear</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>?</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;What</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>,</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;ho</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>!</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;you</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;men</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>,</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;you</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;beasts</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>,</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>That</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;quench</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;the</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;fire</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;of</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;your</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;per</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>n</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>icious</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;rage</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>With</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;pur</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>ple</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;fount</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>ains</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;is</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>su</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>ing</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;from</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;your</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;veins</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>!</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>On</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;pain</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;of</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;torture</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>,</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;from</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;those</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;bloody</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;hands</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>Th</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>row</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;your</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;mist</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>em</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>pe</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>red</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;weapons</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;to</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;the</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;ground</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>And</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;hear</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;the</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;sentence</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;of</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;your</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;moved</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;prince</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>.</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>Three</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;civil</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;braw</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>ls</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>,</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;bred</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;of</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;an</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;air</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>y</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;word</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>By</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;thee</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>,</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;old</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;Capulet</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>,</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;and</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;Montague</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>,</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>Have</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;thrice</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;dist</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>urb</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>'</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>d</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;the</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;quiet</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;of</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;our</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;streets</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>And</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;made</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;Verona</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>'</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>s</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;ancient</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;citizens</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>C</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>ast</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;by</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;their</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;grave</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;bes</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>eem</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>ing</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;orn</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>am</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>ents</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>To</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;w</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>ield</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;old</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;part</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>is</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>ans</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>,</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;in</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;hands</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;as</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;old</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>,</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>Can</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>k</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>'</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>red</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;with</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;peace</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>,</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;to</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;part</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;your</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;can</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>k</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>'</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>red</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;hate</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>.</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>If</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;ever</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;you</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;dist</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>urb</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;our</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;streets</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;again</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>,</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>Your</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;lives</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;shall</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;pay</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;the</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;forfeit</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;of</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;the</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;peace</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>.</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>For</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;this</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;time</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;all</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;the</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;rest</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;depart</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;away</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>.</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>You</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>,</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;Capulet</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>,</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;shall</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;go</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;along</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;with</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;me</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>;</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>And</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>,</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;Montague</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>,</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;come</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;you</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;this</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;afternoon</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>,</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>To</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;know</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;our</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;farther</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;pleasure</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;in</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;this</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;case</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>,</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'><br></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sp, encoder, decoder = get_spm_assets(SPM_MODEL_PATH)\n",
    "MASK_TOKEN_STR = \"[MASK]\"\n",
    "MASK_TOKEN_INT = encoder(MASK_TOKEN_STR)\n",
    "\n",
    "viz_tool = TokenVisualization(encoder, decoder, background_color=\"#FBFBFB\", transparency=0.4)\n",
    "train_df = pd.read_csv(DATA_CSV_PATH)\n",
    "meta_df  = pd.read_csv(META_CSV_PATH)\n",
    "\n",
    "display(train_df)\n",
    "display(meta_df)\n",
    "\n",
    "_ = viz_tool.visualize(train_df.content.sample(1).values[0], display_inline=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d5570e-b19d-4de3-8014-9206f5271759",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<b>Create Datasets</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c15f7871-e2ba-44c2-b4fb-974c7985ee3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<MapDataset element_spec=TensorSpec(shape=(384,), dtype=tf.int64, name=None)>,\n",
       " <MapDataset element_spec=TensorSpec(shape=(384,), dtype=tf.int64, name=None)>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all tfrecords and shuffle\n",
    "ALL_TFRECORDS = glob(os.path.join(TFRECORD_DIR, \"*.tfrec\"))\n",
    "random.shuffle(ALL_TFRECORDS)\n",
    "N_TOTAL_RECS = len(ALL_TFRECORDS)\n",
    "\n",
    "\n",
    "EX_PER_TFREC = 100\n",
    "VAL_PCT = 0.125\n",
    "N_VAL_RECS = int(VAL_PCT*N_TOTAL_RECS)\n",
    "\n",
    "VAL_TFRECORDS = ALL_TFRECORDS[:N_VAL_RECS]\n",
    "TRAIN_TFRECORDS = ALL_TFRECORDS[N_VAL_RECS:]\n",
    "\n",
    "train_ds = load_tfrecord_dataset(TRAIN_TFRECORDS)\n",
    "val_ds = load_tfrecord_dataset(VAL_TFRECORDS)\n",
    "\n",
    "(train_ds, val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3ab3af-9ce8-444f-943d-6944a3550184",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<b>Training Configuration</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71bf0125-77d4-4f2f-91be-4807a3abcf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = dict(\n",
    "    batch_size=32,\n",
    "    shuffle_buffer=512,\n",
    "    encoder_context_len=128,\n",
    "    decoder_context_len=64,\n",
    "    mask_token_id=sp.encode(\"[MASK]\")[0],\n",
    "    vocab_size=sp.vocab_size(),\n",
    "    n_epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c91c42-6f70-4430-85e8-eb7c4dbdeac8",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<b>TF.Data Pipeline</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddfef8be-bcba-4ee1-8208-3fda9babea73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PrefetchDataset element_spec=((TensorSpec(shape=(32, 128), dtype=tf.int32, name=None), TensorSpec(shape=(32, 64), dtype=tf.int32, name=None)), (TensorSpec(shape=(32, 128), dtype=tf.int32, name=None), TensorSpec(shape=(32, 64), dtype=tf.int32, name=None)), (TensorSpec(shape=(32, 128), dtype=tf.float32, name=None), TensorSpec(shape=(32, 64), dtype=tf.float32, name=None)))>,\n",
       " <PrefetchDataset element_spec=((TensorSpec(shape=(32, 128), dtype=tf.int32, name=None), TensorSpec(shape=(32, 64), dtype=tf.int32, name=None)), (TensorSpec(shape=(32, 128), dtype=tf.int32, name=None), TensorSpec(shape=(32, 64), dtype=tf.int32, name=None)), (TensorSpec(shape=(32, 128), dtype=tf.float32, name=None), TensorSpec(shape=(32, 64), dtype=tf.float32, name=None)))>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "# --- Pipeline Steps ---\n",
    "# \n",
    "# 1. Shuffle examples (shuffle_buffer)\n",
    "# 2. Batch examples (batch_size, drop_remainder, AUTOTUNE)\n",
    "# 3. Split sequence into encoder/decoder inputs [`split_on_pivot`]\n",
    "# 4. Split encoder inputs into:\n",
    "#       --> 'inputs' (masked sequence)\n",
    "#       --> 'labels' (unaltered sequence)\n",
    "#       --> 'weights' (sample weights; 1.0 for masked tokens and 0.0 for non-mask tokens)\n",
    "# 5. Split decoder inputs into:\n",
    "#       --> 'inputs' (unaltered sequence)\n",
    "#       --> 'labels' (sequence shifted by 1)\n",
    "\n",
    "def split_on_pivot(tokens: tf.Tensor, \n",
    "                   encoder_context_len: int = 128, \n",
    "                   decoder_context_len: int = 64, \n",
    "                   seq_len: int = 384) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "    \"\"\" Sample encoder and decoder input sequences from a batch of tokens with random pivot indices.\n",
    "    \n",
    "    Args:\n",
    "        tokens: A batch of token sequences with shape (batch_size, seq_len).\n",
    "        encoder_context_len: The number of tokens to be sampled for the encoder input sequences.\n",
    "        decoder_context_len: The number of tokens to be sampled for the decoder input sequences.\n",
    "        seq_len: The total length of each token sequence in the batch.\n",
    "\n",
    "    Returns:\n",
    "        encoder_inputs: A tensor with shape (batch_size, encoder_context_len) containing the\n",
    "                        sampled encoder input sequences.\n",
    "        decoder_inputs: A tensor with shape (batch_size, decoder_context_len) containing the\n",
    "                        sampled decoder input sequences.\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: If the sum of encoder_context_len and decoder_context_len is greater than seq_len.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add one to our decoder context length as we need it for AR head\n",
    "    decoder_context_len+=1\n",
    "    \n",
    "    assert encoder_context_len + decoder_context_len <= seq_len\n",
    "    batch_size = tf.shape(tokens)[0]\n",
    "    c_point = seq_len // 2\n",
    "\n",
    "    # Sample random pivot indices for each sequence in the batch\n",
    "    pivot_indices = tf.random.uniform((batch_size, 1), minval=c_point - (c_point - encoder_context_len),\n",
    "                                      maxval=c_point + (c_point - decoder_context_len), dtype=tf.int32)\n",
    "\n",
    "    # Extract indices for examples before and after the pivot\n",
    "    indices_before = tf.range(-encoder_context_len, 0, dtype=tf.int32)\n",
    "    indices_after = tf.range(1, decoder_context_len + 1, dtype=tf.int32)\n",
    "\n",
    "    # Compute the final indices for sampling from the data\n",
    "    indices_before = tf.expand_dims(pivot_indices, 1) + indices_before\n",
    "    indices_after = tf.expand_dims(pivot_indices, 1) + indices_after\n",
    "\n",
    "    # Gather the corresponding examples from the data\n",
    "    encoder_inputs = tf.squeeze(tf.gather(tokens, indices_before, axis=1, batch_dims=1))\n",
    "    decoder_inputs = tf.squeeze(tf.gather(tokens, indices_after, axis=1, batch_dims=1))\n",
    "\n",
    "    # Reshape the encoder_inputs and decoder_inputs tensors\n",
    "    encoder_inputs = tf.reshape(encoder_inputs, (batch_size, encoder_context_len))\n",
    "    decoder_inputs = tf.reshape(decoder_inputs, (batch_size, decoder_context_len))\n",
    "\n",
    "    return tf.cast(encoder_inputs, tf.int32), tf.cast(decoder_inputs, tf.int32)\n",
    "\n",
    "def mask_sequence(sequence, vocab_size, mask_token_id, pct_to_mask=0.15, pct_to_random=0.1, pct_to_keep=0.1):\n",
    "        \"\"\" Mask a sequence of tokens. \"\"\"\n",
    "\n",
    "        # Calculate the probability of masking each token\n",
    "        masking_prob = tf.random.uniform(shape=tf.shape(sequence), minval=0, maxval=1)\n",
    "\n",
    "        # Calculate the mask based on the masking probability\n",
    "        mask = tf.cast(masking_prob < pct_to_mask, tf.int32)\n",
    "\n",
    "        # Calculate the probability of replacing with a random token\n",
    "        random_prob_mask = tf.cast(masking_prob < (pct_to_mask * pct_to_random), tf.int32)\n",
    "\n",
    "        # Calculate the probability of keeping the original token\n",
    "        keep_prob_mask = tf.cast(masking_prob < (pct_to_mask * pct_to_keep), tf.int32)\n",
    "\n",
    "        # Replace the masked tokens with the mask_token_id\n",
    "        masked_sequence = tf.where(mask == 1, mask_token_id * tf.ones_like(sequence, dtype=tf.int32), sequence)\n",
    "\n",
    "        # Replace random_prob_mask tokens with random tokens\n",
    "        random_tokens = tf.random.uniform(\n",
    "            shape=tf.shape(sequence), minval=0, maxval=vocab_size, dtype=tf.int32\n",
    "        )\n",
    "\n",
    "        # Replace the masked tokens with the mask_token_id\n",
    "        masked_sequence = tf.where(random_prob_mask == 1, random_tokens, masked_sequence)\n",
    "\n",
    "        # Keep the original tokens for keep_prob_mask\n",
    "        masked_sequence = tf.where(keep_prob_mask == 1, sequence, masked_sequence)\n",
    "\n",
    "        # Generate sample weights for masked tokens\n",
    "        sample_weights = tf.cast(mask, tf.float32)\n",
    "\n",
    "        return masked_sequence, sequence, sample_weights\n",
    "\n",
    "\n",
    "def shift_and_split_decoder_inputs(x: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "    \"\"\" TBD \"\"\"\n",
    "    window_size = tf.shape(x)[1]-1\n",
    "    \n",
    "    # Get the indices for the first and second vectors\n",
    "    input_indices = tf.range(0, window_size, dtype=tf.int32)\n",
    "    output_indices = tf.range(1, window_size+1, dtype=tf.int32)\n",
    "\n",
    "    # Gather the corresponding columns for the first and second vectors\n",
    "    decoder_inputs = tf.gather(x, input_indices, axis=-1)\n",
    "    decoder_outputs = tf.gather(x, output_indices, axis=-1)\n",
    "\n",
    "    return decoder_inputs, decoder_outputs\n",
    "    \n",
    "def transform_sequence(sequence, vocab_size, mask_token_id):\n",
    "    encoder_inputs, decoder_inputs = split_on_pivot(sequence)\n",
    "    \n",
    "    # Encoder transform\n",
    "    encoder_inputs, encoder_labels, encoder_sample_wts = mask_sequence(\n",
    "        encoder_inputs, vocab_size, tf.constant(MASK_TOKEN_INT, dtype=tf.int32)\n",
    "    )\n",
    "    \n",
    "    # Decoder transform\n",
    "    decoder_inputs, decoder_labels = shift_and_split_decoder_inputs(decoder_inputs)\n",
    "    decoder_sample_wts = tf.ones_like(decoder_labels, dtype=tf.float32)\n",
    "    \n",
    "    _inputs = (encoder_inputs, decoder_inputs)\n",
    "    _labels = (encoder_labels, decoder_labels)\n",
    "    _sample_wts = (encoder_sample_wts, decoder_sample_wts)\n",
    "    return _inputs, _labels, _sample_wts\n",
    "    \n",
    "    \n",
    "train_ds = train_ds.shuffle(train_config[\"shuffle_buffer\"])\\\n",
    "                   .batch(train_config[\"batch_size\"], drop_remainder=True)\\\n",
    "                   .map(lambda x: transform_sequence(x, train_config[\"vocab_size\"], train_config[\"mask_token_id\"]), num_parallel_calls=tf.data.AUTOTUNE)\\\n",
    "                   .prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds = val_ds.shuffle(train_config[\"shuffle_buffer\"])\\\n",
    "               .batch(train_config[\"batch_size\"], drop_remainder=True)\\\n",
    "               .map(lambda x: transform_sequence(x, train_config[\"vocab_size\"], train_config[\"mask_token_id\"]), num_parallel_calls=tf.data.AUTOTUNE)\\\n",
    "               .prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "train_ds, val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09fc0ae5-367e-4856-a691-2020ed6c2a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_inputs, _labels, _wts = next(iter(val_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80d68ebc-ca75-4c1d-bd54-5cdb3290fab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>span.token {font-family: Courier New; font-size: 1.1em; font-weight: 300; padding: 0px; margin-right: 0px; border-color: rgba(0, 0, 0, 0.05); border-style: ridge; border-radius: 0px;}</style><div style='background-color: #FBFBFB; line-height: 175%; padding: 25px; border-radius: 8px; margin-left: 10px; margin-right: 10px; margin-top: 20px; margin-bottom: 20px; overflow-x: auto; white-space: nowrap;'><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;drops</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;of</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;b</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>alm</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;to</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;sanct</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>ify</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;thy</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;head</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>;</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>[MASK]</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;comp</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>ound</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;me</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;with</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;forgot</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>[MASK]</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;dust</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>;</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>[MASK]</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;that</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;which</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;gave</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;thee</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>[MASK]</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;unto</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;the</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;wor</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>ms</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>.</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>[MASK]</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>Pl</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>[MASK]</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;down</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;my</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;officers</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>,</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;break</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>[MASK]</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;dec</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>rees</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>[MASK]</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>For</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;now</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;a</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;time</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>[MASK]</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;come</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;to</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;mock</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>[MASK]</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;form</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>-</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>[MASK]</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>arry</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;the</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;F</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>[MASK]</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>th</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;is</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;crown</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>[MASK]</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>d</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>.</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;U</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>p</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>,</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;van</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>ity</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>:</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>[MASK]</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>D</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>own</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>,</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>[MASK]</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;state</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>.</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;All</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;you</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;sa</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>ge</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;coun</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>[MASK]</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>ors</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>,</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;hence</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>.</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>[MASK]</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>And</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;to</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;the</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;English</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;court</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;as</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>semble</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;now</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>,</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>From</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>[MASK]</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>[MASK]</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>ion</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>,</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;a</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>pes</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;of</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;id</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>leness</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>.</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>Now</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>,</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;neighbour</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;conf</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'><br></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>span.token {font-family: Courier New; font-size: 1.1em; font-weight: 300; padding: 0px; margin-right: 0px; border-color: rgba(0, 0, 0, 0.05); border-style: ridge; border-radius: 0px;}</style><div style='background-color: #FBFBFB; line-height: 175%; padding: 25px; border-radius: 8px; margin-left: 10px; margin-right: 10px; margin-top: 20px; margin-bottom: 20px; overflow-x: auto; white-space: nowrap;'><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>,</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;pur</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>ge</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;you</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;of</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;your</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;sc</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>um</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>.</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>Have</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;you</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;a</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;ruff</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>ian</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;that</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;will</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;swear</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>,</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;drink</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>,</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;dance</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>,</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>Re</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>vel</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;the</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;night</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>,</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;rob</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>,</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;murder</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>,</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;and</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;commit</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>The</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;old</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>est</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;sins</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;the</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;new</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>est</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;kind</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;of</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;ways</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>?</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>Be</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;happy</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>,</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;he</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;will</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;trouble</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;you</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;no</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;more</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>.</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'><br></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>span.token {font-family: Courier New; font-size: 1.1em; font-weight: 300; padding: 0px; margin-right: 0px; border-color: rgba(0, 0, 0, 0.05); border-style: ridge; border-radius: 0px;}</style><div style='background-color: #FBFBFB; line-height: 175%; padding: 25px; border-radius: 8px; margin-left: 10px; margin-right: 10px; margin-top: 20px; margin-bottom: 20px; overflow-x: auto; white-space: nowrap;'><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;drops</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;of</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;b</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>alm</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;to</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;sanct</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>ify</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;thy</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;head</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>;</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>Only</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;comp</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>ound</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;me</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;with</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;forgot</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>ten</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;dust</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>;</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>Give</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;that</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;which</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;gave</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;thee</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;life</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;unto</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;the</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;wor</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>ms</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>.</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>Pl</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>uck</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;down</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;my</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;officers</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>,</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;break</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;my</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;dec</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>rees</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>;</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>For</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;now</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;a</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;time</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;is</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;come</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;to</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;mock</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;at</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;form</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>-</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>H</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>arry</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;the</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;F</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>if</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>th</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;is</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;crown</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>'</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>d</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>.</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;U</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>p</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>,</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;van</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>ity</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>:</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>D</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>own</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>,</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;royal</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;state</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>.</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;All</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;you</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;sa</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>ge</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;coun</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>sell</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>ors</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>,</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;hence</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>.</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>And</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;to</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;the</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;English</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;court</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;as</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>semble</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;now</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>,</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>From</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;every</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;reg</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>ion</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>,</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;a</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>pes</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;of</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;id</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>leness</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>.</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>Now</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>,</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;neighbour</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;conf</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'><br></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>span.token {font-family: Courier New; font-size: 1.1em; font-weight: 300; padding: 0px; margin-right: 0px; border-color: rgba(0, 0, 0, 0.05); border-style: ridge; border-radius: 0px;}</style><div style='background-color: #FBFBFB; line-height: 175%; padding: 25px; border-radius: 8px; margin-left: 10px; margin-right: 10px; margin-top: 20px; margin-bottom: 20px; overflow-x: auto; white-space: nowrap;'><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;pur</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>ge</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;you</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;of</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;your</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;sc</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>um</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>.</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>Have</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;you</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;a</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;ruff</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>ian</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;that</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;will</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;swear</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>,</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;drink</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>,</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;dance</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>,</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>Re</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>vel</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;the</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;night</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>,</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;rob</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>,</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;murder</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>,</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;and</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;commit</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>The</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;old</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>est</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;sins</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;the</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;new</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>est</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;kind</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;of</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;ways</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>?</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>Be</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;happy</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>,</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;he</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;will</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;trouble</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;you</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;no</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;more</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>.</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'><br></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = viz_tool(_inputs[0][0].numpy().tolist(), display_inline=True)\n",
    "_ = viz_tool(_inputs[1][0].numpy().tolist(), display_inline=True)\n",
    "\n",
    "_ = viz_tool(_labels[0][0].numpy().tolist(), display_inline=True)\n",
    "_ = viz_tool(_labels[1][0].numpy().tolist(), display_inline=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4b7f79-3ca9-4f26-a24d-79cf1c4868b4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\" style=\"font-size: 12px;\">\n",
    "<br><center><b style=\"font-size: 18px;\">TensorFloat-32 Warning:</b></center><br>This warning is related to the use of <b>TensorFloat-32</b> (<b>TF32</b>) in TensorFlow on NVIDIA Ampere architecture GPUs. <b>TensorFloat-32</b> is a new math mode in NVIDIA's A100 GPU for accelerating mixed-precision training in deep learning models. <b>TF32</b> combines the speed of lower-precision FP16 (half-precision) with the dynamic range of FP32 (single-precision).\n",
    "<br><br>\n",
    "The warning message you see is informing you that TensorFlow is using <b>TensorFloat-32</b> for matrix multiplication operations on the GPU. This is expected behavior and does not indicate a problem with your code or model. The warning message is logged only once to let you know that <b>TensorFloat-32</b> is being used for matrix multiplications.\n",
    "<br><br>\n",
    "<b>In most cases, using TensorFloat-32 can lead to significant speed improvements in training deep learning models without negatively impacting the model's accuracy or convergence.</b><br><br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e31cad0-a7a4-4fc3-b9d6-e4349a6aaca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cllm\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " transformer_encoder (Transf  multiple                 2835456   \n",
      " ormerEncoder)                                                   \n",
      "                                                                 \n",
      " transformer_decoder (Transf  multiple                 3358720   \n",
      " ormerDecoder)                                                   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,194,176\n",
      "Trainable params: 6,194,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[ 0.00122931, -0.00095357, -0.01183734, ..., -0.00827219,\n",
       "          -0.00268872, -0.02040298],\n",
       "         [ 0.00508671, -0.00096983, -0.00961313, ..., -0.01311184,\n",
       "          -0.00764793, -0.02018817],\n",
       "         [ 0.00446914,  0.0100721 , -0.01147282, ..., -0.00699435,\n",
       "          -0.00724797, -0.00494835],\n",
       "         ...,\n",
       "         [-0.00913095, -0.01012567, -0.01302268, ...,  0.00353795,\n",
       "          -0.00450482, -0.02274027],\n",
       "         [-0.00487253, -0.01187996, -0.01218519, ..., -0.00332531,\n",
       "          -0.00837998, -0.02055086],\n",
       "         [-0.00235857, -0.00119126, -0.01370125, ...,  0.00077477,\n",
       "          -0.01173878, -0.01417518]],\n",
       " \n",
       "        [[-0.00517943,  0.00559564, -0.00861732, ..., -0.00070297,\n",
       "          -0.0050701 , -0.002491  ],\n",
       "         [ 0.00578697,  0.00692591, -0.009928  , ..., -0.01175569,\n",
       "          -0.01015619, -0.00861843],\n",
       "         [-0.00335376, -0.00390136, -0.01253616, ...,  0.00590277,\n",
       "          -0.00479247,  0.01420439],\n",
       "         ...,\n",
       "         [-0.01419794, -0.01189836, -0.01155422, ...,  0.01084568,\n",
       "          -0.00233965, -0.00803321],\n",
       "         [-0.01346242, -0.00295818, -0.0070215 , ..., -0.0036114 ,\n",
       "          -0.0094303 , -0.00833751],\n",
       "         [-0.0007964 , -0.00689103, -0.01326289, ..., -0.0031651 ,\n",
       "          -0.01353709, -0.00123059]],\n",
       " \n",
       "        [[-0.0017495 , -0.00044436,  0.00384692, ...,  0.00095238,\n",
       "          -0.00189736, -0.00234902],\n",
       "         [ 0.01283967,  0.00542118, -0.00461494, ..., -0.00080074,\n",
       "          -0.01726874,  0.00241184],\n",
       "         [ 0.00335544,  0.00918306, -0.01170717, ..., -0.00658795,\n",
       "          -0.00719665, -0.00580647],\n",
       "         ...,\n",
       "         [-0.01038744, -0.01085729, -0.01088318, ...,  0.0033893 ,\n",
       "          -0.01134523, -0.01730001],\n",
       "         [-0.00431998, -0.00055117, -0.01751819, ...,  0.00918704,\n",
       "          -0.00087146, -0.01451308],\n",
       "         [-0.00304979, -0.00233036, -0.01359708, ...,  0.00203654,\n",
       "          -0.01181305, -0.01533188]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.00095278, -0.00079921, -0.01245522, ..., -0.00819389,\n",
       "          -0.00309252, -0.02008115],\n",
       "         [ 0.00241339,  0.01558378, -0.01155333, ..., -0.00322581,\n",
       "          -0.00376867, -0.00834577],\n",
       "         [ 0.00759764, -0.00565029, -0.01025768, ..., -0.01628336,\n",
       "          -0.011088  , -0.01847807],\n",
       "         ...,\n",
       "         [-0.01555988, -0.01487267, -0.0116254 , ...,  0.00387246,\n",
       "          -0.01561487, -0.0067387 ],\n",
       "         [-0.0213652 , -0.01455595, -0.01824385, ...,  0.00975756,\n",
       "          -0.0091534 , -0.01099029],\n",
       "         [ 0.01227591, -0.00768326, -0.01093473, ...,  0.00920226,\n",
       "          -0.02108491,  0.01157099]],\n",
       " \n",
       "        [[ 0.01893579,  0.00918949, -0.0207698 , ...,  0.0114837 ,\n",
       "          -0.00344547,  0.00429656],\n",
       "         [-0.00045903,  0.0133897 ,  0.0068998 , ...,  0.00014575,\n",
       "          -0.00733825, -0.00243972],\n",
       "         [ 0.00292746,  0.00914478, -0.01166775, ..., -0.00647584,\n",
       "          -0.00715686, -0.0061245 ],\n",
       "         ...,\n",
       "         [-0.01117241, -0.01501415, -0.00743087, ...,  0.00448231,\n",
       "          -0.00673067, -0.00377215],\n",
       "         [-0.00159511, -0.00541645, -0.01049008, ..., -0.00710911,\n",
       "          -0.01996977, -0.00580497],\n",
       "         [ 0.00244978, -0.01445232, -0.00568359, ..., -0.00561648,\n",
       "          -0.0229397 , -0.00949715]],\n",
       " \n",
       "        [[ 0.00118054,  0.01727733, -0.01361159, ...,  0.00024435,\n",
       "           0.00188125, -0.01183254],\n",
       "         [ 0.00467564, -0.00096951, -0.01034833, ..., -0.01308102,\n",
       "          -0.00834686, -0.01942097],\n",
       "         [ 0.00751334, -0.00576948, -0.01045862, ..., -0.01626618,\n",
       "          -0.01132744, -0.01796558],\n",
       "         ...,\n",
       "         [-0.01299548, -0.0077891 , -0.01193832, ...,  0.01130749,\n",
       "           0.00311692, -0.02729434],\n",
       "         [-0.00562862, -0.00888704, -0.00678829, ...,  0.01063172,\n",
       "          -0.00600882, -0.00397383],\n",
       "         [ 0.00090601, -0.00910232, -0.0082077 , ..., -0.00308754,\n",
       "          -0.01772419, -0.00644865]]], dtype=float32),\n",
       " array([[[ 4.4604734e-04,  1.7792366e-04,  2.7622405e-04, ...,\n",
       "          -6.1627897e-04,  4.1656379e-04,  1.5130395e-04],\n",
       "         [ 4.4512097e-04,  2.2755798e-04,  1.7260133e-04, ...,\n",
       "          -4.7708693e-04,  4.8558967e-04, -3.3472134e-06],\n",
       "         [ 4.4361697e-04,  3.3913154e-04,  1.9412076e-04, ...,\n",
       "          -3.5714111e-04,  5.6315667e-04, -9.4938528e-05],\n",
       "         ...,\n",
       "         [ 8.3356467e-04, -4.3002079e-04, -5.2271640e-05, ...,\n",
       "          -9.0501882e-04,  1.2267593e-04,  4.6900357e-04],\n",
       "         [ 8.1334298e-04, -2.3479838e-04, -5.1601382e-05, ...,\n",
       "          -8.2715962e-04,  6.9408954e-05,  6.4620894e-04],\n",
       "         [ 8.5534429e-04, -9.9789788e-05,  1.5184862e-05, ...,\n",
       "          -7.1924832e-04,  2.8389288e-05,  6.0506241e-04]],\n",
       " \n",
       "        [[ 4.9446261e-04, -7.1636052e-05,  1.3708537e-04, ...,\n",
       "          -6.8355794e-04, -8.7899934e-05,  4.8888259e-04],\n",
       "         [ 3.3232523e-04,  1.9224569e-04, -1.0432570e-04, ...,\n",
       "          -6.3873298e-04,  8.8722096e-04,  4.2326996e-04],\n",
       "         [ 1.9306919e-04,  3.6641504e-04,  1.9680630e-04, ...,\n",
       "          -5.2081796e-05,  5.6342749e-05,  4.2804927e-04],\n",
       "         ...,\n",
       "         [ 8.4579858e-04, -4.8613609e-04, -1.3433531e-04, ...,\n",
       "          -8.5298350e-04,  6.3621104e-05,  4.8288653e-04],\n",
       "         [ 8.2517695e-04, -2.8879289e-04, -1.3588210e-04, ...,\n",
       "          -7.7828957e-04,  9.6425210e-06,  6.6135387e-04],\n",
       "         [ 8.6653739e-04, -1.5176315e-04, -7.0035647e-05, ...,\n",
       "          -6.7304389e-04, -2.9557559e-05,  6.2022638e-04]],\n",
       " \n",
       "        [[ 7.4965198e-04,  1.7595121e-04,  1.5580271e-04, ...,\n",
       "          -7.2621857e-04,  4.0745089e-04,  4.3719020e-04],\n",
       "         [ 7.1782176e-04,  6.8427302e-04, -1.6325698e-04, ...,\n",
       "          -5.3913600e-04,  6.5147021e-04,  4.5492483e-04],\n",
       "         [ 5.6044263e-04,  5.5359770e-04, -1.1556199e-04, ...,\n",
       "          -3.3967182e-04,  7.2250492e-04,  5.2077643e-04],\n",
       "         ...,\n",
       "         [ 8.7770709e-04,  6.7722118e-05, -6.2278798e-04, ...,\n",
       "          -8.4369339e-04,  3.0797219e-04,  8.6405728e-04],\n",
       "         [ 8.3102629e-04,  7.5038406e-06, -3.6159344e-04, ...,\n",
       "          -1.1279746e-03,  1.8695873e-04,  1.2262274e-03],\n",
       "         [ 1.0658695e-03,  2.1833854e-04, -2.5061175e-04, ...,\n",
       "          -5.0419359e-04, -3.6078869e-05,  9.4838679e-04]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5.8002834e-04,  3.9033289e-04, -5.3861168e-05, ...,\n",
       "          -6.2654552e-04,  5.8153050e-04,  7.7879702e-04],\n",
       "         [ 3.7332281e-04,  5.4105086e-04,  7.6966964e-05, ...,\n",
       "          -2.5062604e-04, -8.7237022e-05,  2.8944429e-04],\n",
       "         [ 3.3363636e-04,  4.0174837e-04, -1.0416363e-04, ...,\n",
       "          -2.8016118e-04,  4.1495007e-04,  3.4609079e-04],\n",
       "         ...,\n",
       "         [ 7.3075766e-04, -6.0776557e-04, -1.0711263e-04, ...,\n",
       "          -1.0143965e-03, -2.1972768e-04,  8.5975102e-04],\n",
       "         [ 9.0589904e-04,  9.8249875e-05, -5.6902754e-05, ...,\n",
       "          -8.0034108e-04,  2.6136017e-04,  9.2710997e-04],\n",
       "         [ 1.0267424e-03, -1.1714702e-04,  1.1542077e-04, ...,\n",
       "          -7.3721359e-04, -3.5857083e-04,  7.5659202e-04]],\n",
       " \n",
       "        [[ 8.3720573e-04,  5.7294359e-04,  2.0641563e-04, ...,\n",
       "          -3.2374833e-04,  1.2603843e-04,  4.0280691e-04],\n",
       "         [ 4.3974494e-04,  2.5648100e-04,  1.5670888e-04, ...,\n",
       "          -5.7910610e-04,  5.5115751e-04,  3.6160371e-04],\n",
       "         [ 6.3301780e-04,  5.0671218e-04, -3.7830410e-04, ...,\n",
       "          -4.9277284e-04,  5.9219025e-04, -3.3816701e-05],\n",
       "         ...,\n",
       "         [ 5.9266039e-04, -4.2021289e-04, -4.1280556e-04, ...,\n",
       "          -7.2740979e-04, -1.9746754e-04,  1.0769250e-03],\n",
       "         [ 6.9228193e-04,  1.5337937e-04, -1.9808290e-04, ...,\n",
       "          -8.8638160e-04, -2.4589160e-04,  9.7284035e-04],\n",
       "         [ 1.0770311e-03,  2.1347735e-04, -2.5743552e-04, ...,\n",
       "          -4.9672276e-04, -3.6050667e-05,  9.4485923e-04]],\n",
       " \n",
       "        [[ 5.6915038e-04,  2.6103892e-04, -1.4708485e-04, ...,\n",
       "          -5.5177638e-04,  5.1533961e-04,  3.9078676e-04],\n",
       "         [ 6.4881949e-04, -5.7563375e-07, -4.2693183e-04, ...,\n",
       "          -4.0494691e-04,  4.4489827e-04,  2.0843209e-04],\n",
       "         [ 4.9989781e-04,  3.2640490e-04,  2.3492347e-04, ...,\n",
       "          -4.5667385e-04,  6.2552298e-04,  1.3752189e-04],\n",
       "         ...,\n",
       "         [ 5.0172658e-04, -6.4963981e-04, -3.7500518e-05, ...,\n",
       "          -5.5853906e-04, -5.1392766e-04,  1.0696405e-03],\n",
       "         [ 9.8322390e-04, -1.2294599e-04, -8.6474312e-05, ...,\n",
       "          -7.5276784e-04, -1.7548022e-04,  1.1704703e-03],\n",
       "         [ 8.7256962e-04,  2.5565500e-05, -1.3351683e-04, ...,\n",
       "          -7.4364425e-04, -3.4707569e-05,  8.6887047e-04]]], dtype=float32))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spearecode.models.cllm_backbone import CLLM\n",
    "\n",
    "# --- Model Steps ---\n",
    "# \n",
    "# 1. Define Configurations\n",
    "# 2. Load Model Architecture\n",
    "# 3. Define Optimizer and Learning Rate Details\n",
    "# 4. Define Callbacks\n",
    "#       --> TBD\n",
    "#       --> TBD\n",
    "#       --> TBD\n",
    "# 5. Define Loss Functions\n",
    "#       --> MLM Loss\n",
    "#       --> AR Loss\n",
    "# 6. Define Metrics\n",
    "#       --> TBD\n",
    "#       --> TBD\n",
    "\n",
    "enc_vocab_size, dec_vocab_size       = sp.vocab_size(), sp.vocab_size()\n",
    "enc_context_len, dec_context_len     = 128, 64\n",
    "enc_embed_dim, dec_embed_dim         = 128, 128\n",
    "enc_hidden_layers, dec_hidden_layers = 2, 2\n",
    "enc_attn_heads, dec_attn_heads       = 4, 4\n",
    "enc_ffn_act, dec_ffn_act             = \"gelu\", \"gelu\"\n",
    "enc_ffn_dropout, dec_ffn_dropout     = 0.1, 0.1\n",
    "enc_attn_dropout, dec_attn_dropout   = 0.1, 0.1\n",
    "enc_use_bias, dec_use_bias           = False, False\n",
    "enc_expansion, dec_expansion         = 4, 4\n",
    "\n",
    "enc_config = dict(\n",
    "    vocab_size=enc_vocab_size,\n",
    "    context_length=enc_context_len,\n",
    "    embedding_size=enc_embed_dim,\n",
    "    n_heads=enc_attn_heads,\n",
    "    n_layers=enc_hidden_layers,\n",
    "    use_bias=enc_use_bias,\n",
    "    ffn_act=enc_ffn_act,\n",
    "    expansion_factor=enc_expansion,\n",
    "    dropout_rate=enc_ffn_dropout,\n",
    ")\n",
    "\n",
    "dec_config = dict(\n",
    "    vocab_size=dec_vocab_size,\n",
    "    context_length=dec_context_len,\n",
    "    embedding_size=dec_embed_dim,\n",
    "    n_heads=dec_attn_heads,\n",
    "    n_layers=dec_hidden_layers,\n",
    "    use_bias=dec_use_bias,\n",
    "    ffn_act=dec_ffn_act,\n",
    "    expansion_factor=dec_expansion,\n",
    "    dropout_rate=dec_ffn_dropout,\n",
    ")\n",
    "\n",
    "cllm = CLLM(encoder_kwargs=enc_config, decoder_kwargs=dec_config, batch_size=train_config[\"batch_size\"])\n",
    "cllm.summary()\n",
    "\n",
    "# test predict\n",
    "cllm.predict(val_ds.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f4273ac-cfea-4d3d-9b76-a9a25591c841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.optimizers.optimizer_v2.adam.Adam at 0x7f0540246310>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spearecode.optimizers import AdamWeightDecay, WarmUpCosineDecay\n",
    "\n",
    "approx_total_steps = N_TOTAL_RECS*100\n",
    "approx_val_steps = N_VAL_RECS*100\n",
    "approx_train_steps = approx_total_steps-approx_val_steps\n",
    "\n",
    "optimizer_config = dict(\n",
    "    use_basic_adam=True,\n",
    "    use_cdecay_lr=True,\n",
    "    weight_decay_rate=0.1,\n",
    "    clipnorm=True,\n",
    "    gradient_clip_norm=1.0,\n",
    "    beta_1=1.0,\n",
    "    beta_2=0.95,\n",
    "    exclude_from_weight_decay = ['layer_normalization', 'bias'],\n",
    ")\n",
    "\n",
    "lr_config = dict(\n",
    "    init_lr=0.001,\n",
    "    min_lr=5e-05,\n",
    "    decay_portion=1.0,\n",
    "    warmup_portion=0.05,\n",
    "    hold_portion=0.01,\n",
    "    total_steps=approx_train_steps,\n",
    "    alpha=0.0,\n",
    "    decay_steps=approx_train_steps,\n",
    "    warmup_steps=int(approx_train_steps*0.05),\n",
    "    hold_steps=int(approx_train_steps*0.01),\n",
    ")\n",
    "\n",
    "# Instantiate our learning rate (or lr-schedule)\n",
    "if optimizer_config[\"use_cdecay_lr\"]:\n",
    "    optimizer_config.pop(\"use_cdecay_lr\")\n",
    "    lr=WarmUpCosineDecay(**lr_config)\n",
    "else:\n",
    "    lr=lr_config[\"init_lr\"]\n",
    "\n",
    "# Instantiate our optimizer (AdamW or just vanilla Adam)\n",
    "if not optimizer_config[\"use_basic_adam\"]:\n",
    "    optimizer_config.pop(\"use_basic_adam\")\n",
    "    optimizer = AdamWeightDecay(learning_rate=lr, **optimizer_config)\n",
    "else:\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    \n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7c7ac29-d1be-4d3b-bc76-11c47adb870c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.callbacks.ModelCheckpoint at 0x7f052c551400>,\n",
       " <keras.callbacks.EarlyStopping at 0x7f052c5517c0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spearecode.callbacks import get_callbacks\n",
    "\n",
    "CKPT_DIR = os.path.join(MODELS_DIR, \"ckpts\")\n",
    "if not os.path.isdir(CKPT_DIR): os.makedirs(CKPT_DIR, exist_ok=True)\n",
    "\n",
    "cb_config = dict(\n",
    "    ckpt_dir=CKPT_DIR,\n",
    "    save_weights_only=True,\n",
    "    use_early_stopping=True,\n",
    "    es_patience=10,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "cb_list = get_callbacks(cb_config)\n",
    "cb_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9388b85-771f-45f7-a5e2-1ab38ac649b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fns = [\n",
    "    tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), # ENCODER MLM LOSS\n",
    "    tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), # DECODER AR  LOSS\n",
    "]\n",
    "\n",
    "metrics = [\n",
    "    #TBD\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e384fc0-1613-47f8-834b-49fcc2fd882f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "    209/Unknown - 5s 14ms/step - loss: 6.6099 - output_1_loss: 0.9974 - output_2_loss: 5.6125WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 5.20506, saving model to /home/paperspace/home/spearecode/models/ckpts\n",
      "212/212 [==============================] - 6s 18ms/step - loss: 6.5854 - output_1_loss: 0.9942 - output_2_loss: 5.5912 - val_loss: 5.2051 - val_output_1_loss: 0.7840 - val_output_2_loss: 4.4211\n",
      "Epoch 2/100\n",
      "209/212 [============================>.] - ETA: 0s - loss: 4.9010 - output_1_loss: 0.7552 - output_2_loss: 4.1457WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "\n",
      "Epoch 2: val_loss improved from 5.20506 to 4.68722, saving model to /home/paperspace/home/spearecode/models/ckpts\n",
      "212/212 [==============================] - 4s 17ms/step - loss: 4.8985 - output_1_loss: 0.7541 - output_2_loss: 4.1444 - val_loss: 4.6872 - val_output_1_loss: 0.7423 - val_output_2_loss: 3.9449\n",
      "Epoch 3/100\n",
      "209/212 [============================>.] - ETA: 0s - loss: 4.5674 - output_1_loss: 0.7362 - output_2_loss: 3.8312WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "\n",
      "Epoch 3: val_loss improved from 4.68722 to 4.58753, saving model to /home/paperspace/home/spearecode/models/ckpts\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 4.5602 - output_1_loss: 0.7356 - output_2_loss: 3.8247 - val_loss: 4.5875 - val_output_1_loss: 0.7455 - val_output_2_loss: 3.8420\n",
      "Epoch 4/100\n",
      "209/212 [============================>.] - ETA: 0s - loss: 4.4268 - output_1_loss: 0.7338 - output_2_loss: 3.6930WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "\n",
      "Epoch 4: val_loss improved from 4.58753 to 4.45024, saving model to /home/paperspace/home/spearecode/models/ckpts\n",
      "212/212 [==============================] - 4s 16ms/step - loss: 4.4327 - output_1_loss: 0.7343 - output_2_loss: 3.6985 - val_loss: 4.4502 - val_output_1_loss: 0.7465 - val_output_2_loss: 3.7037\n",
      "Epoch 5/100\n",
      "209/212 [============================>.] - ETA: 0s - loss: 4.3358 - output_1_loss: 0.7286 - output_2_loss: 3.6072WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "\n",
      "Epoch 5: val_loss improved from 4.45024 to 4.31344, saving model to /home/paperspace/home/spearecode/models/ckpts\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 4.3375 - output_1_loss: 0.7298 - output_2_loss: 3.6077 - val_loss: 4.3134 - val_output_1_loss: 0.7297 - val_output_2_loss: 3.5837\n",
      "Epoch 6/100\n",
      "209/212 [============================>.] - ETA: 0s - loss: 4.2504 - output_1_loss: 0.7242 - output_2_loss: 3.5262WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "\n",
      "Epoch 6: val_loss did not improve from 4.31344\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 4.2507 - output_1_loss: 0.7243 - output_2_loss: 3.5264 - val_loss: 4.3268 - val_output_1_loss: 0.7391 - val_output_2_loss: 3.5878\n",
      "Epoch 7/100\n",
      "209/212 [============================>.] - ETA: 0s - loss: 4.1208 - output_1_loss: 0.7235 - output_2_loss: 3.3974WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "\n",
      "Epoch 7: val_loss improved from 4.31344 to 4.17539, saving model to /home/paperspace/home/spearecode/models/ckpts\n",
      "212/212 [==============================] - 4s 16ms/step - loss: 4.1210 - output_1_loss: 0.7230 - output_2_loss: 3.3980 - val_loss: 4.1754 - val_output_1_loss: 0.7436 - val_output_2_loss: 3.4318\n",
      "Epoch 8/100\n",
      "209/212 [============================>.] - ETA: 0s - loss: 4.0790 - output_1_loss: 0.7246 - output_2_loss: 3.3544WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "\n",
      "Epoch 8: val_loss improved from 4.17539 to 4.10638, saving model to /home/paperspace/home/spearecode/models/ckpts\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 4.0704 - output_1_loss: 0.7244 - output_2_loss: 3.3460 - val_loss: 4.1064 - val_output_1_loss: 0.7399 - val_output_2_loss: 3.3665\n",
      "Epoch 9/100\n",
      "137/212 [==================>...........] - ETA: 1s - loss: 4.0118 - output_1_loss: 0.7145 - output_2_loss: 3.2973"
     ]
    }
   ],
   "source": [
    "# loss_weights=[0.5, 0.5]\n",
    "# metrics = TBD\n",
    "cllm.compile(optimizer, loss=loss_fns)\n",
    "history = cllm.fit(train_ds, validation_data=val_ds, epochs=train_config[\"n_epochs\"], callbacks=cb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa3251c-9a42-45a2-9044-00441c086b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,s = next(iter(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b11f142-2f49-4203-9680-d434e0e2e6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c86558b-c39e-44a7-bad2-4d71fdcd22fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
