{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0acb0112-c7aa-4f44-b9f2-b00adce49d8e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<b>Imports and Constants</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d4bf6c3-8590-4e25-95f7-24a62edd1c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q --upgrade tokenizer-viz\n",
    "\n",
    "# Regular imports (native python and pypi packages)\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import sentencepiece as spm\n",
    "from IPython.display import HTML, display\n",
    "from tokenizer_viz import TokenVisualization\n",
    "from tqdm.notebook import tqdm; tqdm.pandas()\n",
    "\n",
    "# Add project root into path so imports work\n",
    "PROJECT_DIR = os.path.dirname(os.getcwd())\n",
    "sys.path.insert(0, PROJECT_DIR) \n",
    "\n",
    "# Our project imports\n",
    "from spearecode.preprocessing_utils import (\n",
    "    load_from_txt_file, preprocess_shakespeare, save_to_txt_file, print_check_speare, get_spm_assets\n",
    ")\n",
    "from spearecode.general_utils import (\n",
    "    tf_xla_jit, tf_set_memory_growth, seed_it_all, flatten_l_o_l, print_ln\n",
    ")\n",
    "from spearecode.filtering_utils import (\n",
    "    save_ds_version, drop_str_from_col_names, pad_truncate_centered,\n",
    "    get_metadata_df, check_chunks, tokenize, get_n_tokens,\n",
    "    get_n_lines, get_n_chars\n",
    ")\n",
    "from spearecode.tfrecord_utils import write_tfrecords, load_tfrecord_dataset\n",
    "\n",
    "TRAIN_STYLE = \"rcts_bpe_v4\"\n",
    "CHUNK_STYLE, TOK_STYLE, DS_VERSION = TRAIN_STYLE.split(\"_\")\n",
    "\n",
    "### DEFINE PATHS --- [PROJECT_DIR=\"/home/paperspace/home/spearecode\"] --- ###\n",
    "NBS_PATH = os.path.join(PROJECT_DIR, \"nbs\")\n",
    "DATA_PATH = os.path.join(PROJECT_DIR, \"data\")\n",
    "SS_TEXT_PATH = os.path.join(DATA_PATH, \"t8.shakespeare.txt\")\n",
    "PREPROCESSED_FULL_TEXT_PATH = SS_TEXT_PATH.replace(\".txt\", \"_preprocessed.txt\")\n",
    "\n",
    "DATASETS_PATH = os.path.join(DATA_PATH, \"datasets\") \n",
    "META_DIR = os.path.join(DATASETS_PATH, \"meta\") \n",
    "TFRECORD_DIR = os.path.join(DATASETS_PATH, \"tfrecords\", TRAIN_STYLE)\n",
    "MODELS_DIR = os.path.join(PROJECT_DIR, \"models\")\n",
    "\n",
    "# Specific Paths\n",
    "SPM_MODEL_PATH = os.path.join(MODELS_DIR, f\"spearecode_{TOK_STYLE}\")\n",
    "DATA_CSV_PATH  = os.path.join(DATASETS_PATH, f\"{DS_VERSION}_{CHUNK_STYLE}_{TOK_STYLE}.csv\")\n",
    "META_CSV_PATH  = os.path.join(META_DIR, f\"{DS_VERSION}_{CHUNK_STYLE}_{TOK_STYLE}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2accc846-874c-4bfc-9bef-b01ca883f5a1",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<b>Instantiate expected tools for the reset of the notebook</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2dec0a8-a181-492a-ac75-f397776c522c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>token_content</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>n_lines</th>\n",
       "      <th>valid_chunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1\\n  From fairest creatures we desire increase...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>192</td>\n",
       "      <td>643</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2\\n  When forty winters shall besiege thy brow...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>188</td>\n",
       "      <td>662</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3\\n  Look in thy glass and tell the face thou ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>183</td>\n",
       "      <td>643</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4\\n  Unthrifty loveliness why dost thou spend,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>183</td>\n",
       "      <td>619</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5\\n  Those hours that with gentle work did fra...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>176</td>\n",
       "      <td>652</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7694</th>\n",
       "      <td>'\"Lo, this device was sent me from a nun,\\n  O...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>282</td>\n",
       "      <td>944</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7695</th>\n",
       "      <td>'\"How mighty then you are, O hear me tell!\\n  ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>298</td>\n",
       "      <td>983</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7696</th>\n",
       "      <td>'\"Now all these hearts that do on mine depend,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>283</td>\n",
       "      <td>977</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7697</th>\n",
       "      <td>'For lo, his passion, but an art of craft,\\n  ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>292</td>\n",
       "      <td>965</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7698</th>\n",
       "      <td>'Thus merely with the garment of a Grace  \\n  ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>199</td>\n",
       "      <td>630</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7699 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  \\\n",
       "0     1\\n  From fairest creatures we desire increase...   \n",
       "1     2\\n  When forty winters shall besiege thy brow...   \n",
       "2     3\\n  Look in thy glass and tell the face thou ...   \n",
       "3     4\\n  Unthrifty loveliness why dost thou spend,...   \n",
       "4     5\\n  Those hours that with gentle work did fra...   \n",
       "...                                                 ...   \n",
       "7694  '\"Lo, this device was sent me from a nun,\\n  O...   \n",
       "7695  '\"How mighty then you are, O hear me tell!\\n  ...   \n",
       "7696  '\"Now all these hearts that do on mine depend,...   \n",
       "7697  'For lo, his passion, but an art of craft,\\n  ...   \n",
       "7698  'Thus merely with the garment of a Grace  \\n  ...   \n",
       "\n",
       "                                          token_content  n_tokens  n_chars  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       192      643   \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       188      662   \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       183      643   \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       183      619   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       176      652   \n",
       "...                                                 ...       ...      ...   \n",
       "7694  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       282      944   \n",
       "7695  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       298      983   \n",
       "7696  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       283      977   \n",
       "7697  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       292      965   \n",
       "7698  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       199      630   \n",
       "\n",
       "      n_lines  valid_chunk  \n",
       "0          15         True  \n",
       "1          15         True  \n",
       "2          15         True  \n",
       "3          15         True  \n",
       "4          15         True  \n",
       "...       ...          ...  \n",
       "7694       23         True  \n",
       "7695       23         True  \n",
       "7696       23         True  \n",
       "7697       23         True  \n",
       "7698       15         True  \n",
       "\n",
       "[7699 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>n_lines</th>\n",
       "      <th>valid_chunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192</td>\n",
       "      <td>643</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>662</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>183</td>\n",
       "      <td>643</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>183</td>\n",
       "      <td>619</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>176</td>\n",
       "      <td>652</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7694</th>\n",
       "      <td>282</td>\n",
       "      <td>944</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7695</th>\n",
       "      <td>298</td>\n",
       "      <td>983</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7696</th>\n",
       "      <td>283</td>\n",
       "      <td>977</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7697</th>\n",
       "      <td>292</td>\n",
       "      <td>965</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7698</th>\n",
       "      <td>199</td>\n",
       "      <td>630</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7699 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      n_tokens  n_chars  n_lines  valid_chunk\n",
       "0          192      643       15         True\n",
       "1          188      662       15         True\n",
       "2          183      643       15         True\n",
       "3          183      619       15         True\n",
       "4          176      652       15         True\n",
       "...        ...      ...      ...          ...\n",
       "7694       282      944       23         True\n",
       "7695       298      983       23         True\n",
       "7696       283      977       23         True\n",
       "7697       292      965       23         True\n",
       "7698       199      630       15         True\n",
       "\n",
       "[7699 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>span.token {font-family: Courier New; font-size: 1.1em; font-weight: 300; padding: 0px; margin-right: 0px; border-color: rgba(0, 0, 0, 0.05); border-style: ridge; border-radius: 0px;}</style><div style='background-color: #FBFBFB; line-height: 175%; padding: 25px; border-radius: 8px; margin-left: 10px; margin-right: 10px; margin-top: 20px; margin-bottom: 20px; overflow-x: auto; white-space: nowrap;'><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>R</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>UT</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>LAND</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>.</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;Ah</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>,</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;whither</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;shall</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;I</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;fly</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;to</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;scape</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;their</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;hands</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>?</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>Ah</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>,</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;tut</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>or</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>,</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;look</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;where</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;bloody</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;Clifford</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;comes</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>!</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>Enter</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;CLIFFORD</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;and</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;soldiers</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'><br></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sp, encoder, decoder = get_spm_assets(SPM_MODEL_PATH)\n",
    "MASK_TOKEN_STR = \"[MASK]\"\n",
    "MASK_TOKEN_INT = encoder(MASK_TOKEN_STR)\n",
    "\n",
    "viz_tool = TokenVisualization(encoder, decoder, background_color=\"#FBFBFB\", transparency=0.4)\n",
    "train_df = pd.read_csv(DATA_CSV_PATH)\n",
    "meta_df  = pd.read_csv(META_CSV_PATH)\n",
    "\n",
    "display(train_df)\n",
    "display(meta_df)\n",
    "\n",
    "_ = viz_tool.visualize(train_df.content.sample(1).values[0], display_inline=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d5570e-b19d-4de3-8014-9206f5271759",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<b>Create Datasets</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c15f7871-e2ba-44c2-b4fb-974c7985ee3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<MapDataset element_spec=TensorSpec(shape=(384,), dtype=tf.int64, name=None)>,\n",
       " <MapDataset element_spec=TensorSpec(shape=(384,), dtype=tf.int64, name=None)>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all tfrecords and shuffle\n",
    "ALL_TFRECORDS = glob(os.path.join(TFRECORD_DIR, \"*.tfrec\"))\n",
    "random.shuffle(ALL_TFRECORDS)\n",
    "N_TOTAL_RECS = len(ALL_TFRECORDS)\n",
    "\n",
    "\n",
    "EX_PER_TFREC = 100\n",
    "VAL_PCT = 0.125\n",
    "N_VAL_RECS = int(VAL_PCT*N_TOTAL_RECS)\n",
    "\n",
    "VAL_TFRECORDS = ALL_TFRECORDS[:N_VAL_RECS]\n",
    "TRAIN_TFRECORDS = ALL_TFRECORDS[N_VAL_RECS:]\n",
    "\n",
    "train_ds = load_tfrecord_dataset(TRAIN_TFRECORDS)\n",
    "val_ds = load_tfrecord_dataset(VAL_TFRECORDS)\n",
    "\n",
    "(train_ds, val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3ab3af-9ce8-444f-943d-6944a3550184",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<b>Training Configuration</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71bf0125-77d4-4f2f-91be-4807a3abcf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = dict(\n",
    "    batch_size=32,\n",
    "    shuffle_buffer=512,\n",
    "    encoder_context_len=128,\n",
    "    decoder_context_len=64,\n",
    "    mask_token_id=sp.encode(\"[MASK]\")[0],\n",
    "    vocab_size=sp.vocab_size(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c91c42-6f70-4430-85e8-eb7c4dbdeac8",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<b>TF.Data Pipeline</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddfef8be-bcba-4ee1-8208-3fda9babea73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PrefetchDataset element_spec=((TensorSpec(shape=(32, 128), dtype=tf.int32, name=None), TensorSpec(shape=(32, 64), dtype=tf.int32, name=None)), (TensorSpec(shape=(32, 128), dtype=tf.int32, name=None), TensorSpec(shape=(32, 64), dtype=tf.int32, name=None)), (TensorSpec(shape=(32, 128), dtype=tf.float32, name=None), TensorSpec(shape=(32, 64), dtype=tf.float32, name=None)))>,\n",
       " <PrefetchDataset element_spec=((TensorSpec(shape=(32, 128), dtype=tf.int32, name=None), TensorSpec(shape=(32, 64), dtype=tf.int32, name=None)), (TensorSpec(shape=(32, 128), dtype=tf.int32, name=None), TensorSpec(shape=(32, 64), dtype=tf.int32, name=None)), (TensorSpec(shape=(32, 128), dtype=tf.float32, name=None), TensorSpec(shape=(32, 64), dtype=tf.float32, name=None)))>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "# --- Pipeline Steps ---\n",
    "# \n",
    "# 1. Shuffle examples (shuffle_buffer)\n",
    "# 2. Batch examples (batch_size, drop_remainder, AUTOTUNE)\n",
    "# 3. Split sequence into encoder/decoder inputs [`split_on_pivot`]\n",
    "# 4. Split encoder inputs into:\n",
    "#       --> 'inputs' (masked sequence)\n",
    "#       --> 'labels' (unaltered sequence)\n",
    "#       --> 'weights' (sample weights; 1.0 for masked tokens and 0.0 for non-mask tokens)\n",
    "# 5. Split decoder inputs into:\n",
    "#       --> 'inputs' (unaltered sequence)\n",
    "#       --> 'labels' (sequence shifted by 1)\n",
    "\n",
    "def split_on_pivot(tokens: tf.Tensor, \n",
    "                   encoder_context_len: int = 128, \n",
    "                   decoder_context_len: int = 64, \n",
    "                   seq_len: int = 384) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "    \"\"\" Sample encoder and decoder input sequences from a batch of tokens with random pivot indices.\n",
    "    \n",
    "    Args:\n",
    "        tokens: A batch of token sequences with shape (batch_size, seq_len).\n",
    "        encoder_context_len: The number of tokens to be sampled for the encoder input sequences.\n",
    "        decoder_context_len: The number of tokens to be sampled for the decoder input sequences.\n",
    "        seq_len: The total length of each token sequence in the batch.\n",
    "\n",
    "    Returns:\n",
    "        encoder_inputs: A tensor with shape (batch_size, encoder_context_len) containing the\n",
    "                        sampled encoder input sequences.\n",
    "        decoder_inputs: A tensor with shape (batch_size, decoder_context_len) containing the\n",
    "                        sampled decoder input sequences.\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: If the sum of encoder_context_len and decoder_context_len is greater than seq_len.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add one to our decoder context length as we need it for AR head\n",
    "    decoder_context_len+=1\n",
    "    \n",
    "    assert encoder_context_len + decoder_context_len <= seq_len\n",
    "    batch_size = tf.shape(tokens)[0]\n",
    "    c_point = seq_len // 2\n",
    "\n",
    "    # Sample random pivot indices for each sequence in the batch\n",
    "    pivot_indices = tf.random.uniform((batch_size, 1), minval=c_point - (c_point - encoder_context_len),\n",
    "                                      maxval=c_point + (c_point - decoder_context_len), dtype=tf.int32)\n",
    "\n",
    "    # Extract indices for examples before and after the pivot\n",
    "    indices_before = tf.range(-encoder_context_len, 0, dtype=tf.int32)\n",
    "    indices_after = tf.range(1, decoder_context_len + 1, dtype=tf.int32)\n",
    "\n",
    "    # Compute the final indices for sampling from the data\n",
    "    indices_before = tf.expand_dims(pivot_indices, 1) + indices_before\n",
    "    indices_after = tf.expand_dims(pivot_indices, 1) + indices_after\n",
    "\n",
    "    # Gather the corresponding examples from the data\n",
    "    encoder_inputs = tf.squeeze(tf.gather(tokens, indices_before, axis=1, batch_dims=1))\n",
    "    decoder_inputs = tf.squeeze(tf.gather(tokens, indices_after, axis=1, batch_dims=1))\n",
    "\n",
    "    # Reshape the encoder_inputs and decoder_inputs tensors\n",
    "    encoder_inputs = tf.reshape(encoder_inputs, (batch_size, encoder_context_len))\n",
    "    decoder_inputs = tf.reshape(decoder_inputs, (batch_size, decoder_context_len))\n",
    "\n",
    "    return tf.cast(encoder_inputs, tf.int32), tf.cast(decoder_inputs, tf.int32)\n",
    "\n",
    "def mask_sequence(sequence, vocab_size, mask_token_id, pct_to_mask=0.15, pct_to_random=0.1, pct_to_keep=0.1):\n",
    "        \"\"\" Mask a sequence of tokens. \"\"\"\n",
    "\n",
    "        # Calculate the probability of masking each token\n",
    "        masking_prob = tf.random.uniform(shape=tf.shape(sequence), minval=0, maxval=1)\n",
    "\n",
    "        # Calculate the mask based on the masking probability\n",
    "        mask = tf.cast(masking_prob < pct_to_mask, tf.int32)\n",
    "\n",
    "        # Calculate the probability of replacing with a random token\n",
    "        random_prob_mask = tf.cast(masking_prob < (pct_to_mask * pct_to_random), tf.int32)\n",
    "\n",
    "        # Calculate the probability of keeping the original token\n",
    "        keep_prob_mask = tf.cast(masking_prob < (pct_to_mask * pct_to_keep), tf.int32)\n",
    "\n",
    "        # Replace the masked tokens with the mask_token_id\n",
    "        masked_sequence = tf.where(mask == 1, mask_token_id * tf.ones_like(sequence, dtype=tf.int32), sequence)\n",
    "\n",
    "        # Replace random_prob_mask tokens with random tokens\n",
    "        random_tokens = tf.random.uniform(\n",
    "            shape=tf.shape(sequence), minval=0, maxval=vocab_size, dtype=tf.int32\n",
    "        )\n",
    "\n",
    "        # Replace the masked tokens with the mask_token_id\n",
    "        masked_sequence = tf.where(random_prob_mask == 1, random_tokens, masked_sequence)\n",
    "\n",
    "        # Keep the original tokens for keep_prob_mask\n",
    "        masked_sequence = tf.where(keep_prob_mask == 1, sequence, masked_sequence)\n",
    "\n",
    "        # Generate sample weights for masked tokens\n",
    "        sample_weights = tf.cast(mask, tf.float32)\n",
    "\n",
    "        return masked_sequence, sequence, sample_weights\n",
    "\n",
    "\n",
    "def shift_and_split_decoder_inputs(x: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "    \"\"\" TBD \"\"\"\n",
    "    window_size = tf.shape(x)[1]-1\n",
    "    \n",
    "    # Get the indices for the first and second vectors\n",
    "    input_indices = tf.range(0, window_size, dtype=tf.int32)\n",
    "    output_indices = tf.range(1, window_size+1, dtype=tf.int32)\n",
    "\n",
    "    # Gather the corresponding columns for the first and second vectors\n",
    "    decoder_inputs = tf.gather(x, input_indices, axis=-1)\n",
    "    decoder_outputs = tf.gather(x, output_indices, axis=-1)\n",
    "\n",
    "    return decoder_inputs, decoder_outputs\n",
    "    \n",
    "def transform_sequence(sequence, vocab_size, mask_token_id):\n",
    "    encoder_inputs, decoder_inputs = split_on_pivot(sequence)\n",
    "    \n",
    "    # Encoder transform\n",
    "    encoder_inputs, encoder_labels, encoder_sample_wts = mask_sequence(\n",
    "        encoder_inputs, vocab_size, tf.constant(MASK_TOKEN_INT, dtype=tf.int32)\n",
    "    )\n",
    "    \n",
    "    # Decoder transform\n",
    "    decoder_inputs, decoder_labels = shift_and_split_decoder_inputs(decoder_inputs)\n",
    "    decoder_sample_wts = tf.ones_like(decoder_labels, dtype=tf.float32)\n",
    "    \n",
    "    _inputs = (encoder_inputs, decoder_inputs)\n",
    "    _labels = (encoder_labels, decoder_labels)\n",
    "    _sample_wts = (encoder_sample_wts, decoder_sample_wts)\n",
    "    return _inputs, _labels, _sample_wts\n",
    "    \n",
    "    \n",
    "train_ds = train_ds.shuffle(train_config[\"shuffle_buffer\"])\\\n",
    "                   .batch(train_config[\"batch_size\"], drop_remainder=True)\\\n",
    "                   .map(lambda x: transform_sequence(x, train_config[\"vocab_size\"], train_config[\"mask_token_id\"]), num_parallel_calls=tf.data.AUTOTUNE)\\\n",
    "                   .prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds = val_ds.shuffle(train_config[\"shuffle_buffer\"])\\\n",
    "               .batch(train_config[\"batch_size\"], drop_remainder=True)\\\n",
    "               .map(lambda x: transform_sequence(x, train_config[\"vocab_size\"], train_config[\"mask_token_id\"]), num_parallel_calls=tf.data.AUTOTUNE)\\\n",
    "               .prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "train_ds, val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09fc0ae5-367e-4856-a691-2020ed6c2a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_inputs, _labels, _wts = next(iter(val_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80d68ebc-ca75-4c1d-bd54-5cdb3290fab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>span.token {font-family: Courier New; font-size: 1.1em; font-weight: 300; padding: 0px; margin-right: 0px; border-color: rgba(0, 0, 0, 0.05); border-style: ridge; border-radius: 0px;}</style><div style='background-color: #FBFBFB; line-height: 175%; padding: 25px; border-radius: 8px; margin-left: 10px; margin-right: 10px; margin-top: 20px; margin-bottom: 20px; overflow-x: auto; white-space: nowrap;'><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;friends</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>,</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;where</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;Cleopatra</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;bid</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>es</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>;</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>'</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>[MASK]</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>[MASK]</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;last</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;service</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;that</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;I</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;shall</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;command</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;you</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>.</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>[MASK]</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>[MASK]</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;GUARD</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>.</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;W</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>[MASK]</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>,</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;woe</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;are</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;we</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>,</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;sir</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>,</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;you</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>[MASK]</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;not</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;live</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;to</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;wear</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>[MASK]</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>[MASK]</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;true</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>[MASK]</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>[MASK]</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>.</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>ALL</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>.</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;Most</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;heavy</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;day</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>!</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>ANTONY</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>.</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;Nay</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>,</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;good</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;my</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;fellows</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>,</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>[MASK]</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;not</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;please</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;sharp</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;fate</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>To</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;grace</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;it</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;with</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;your</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;sorrows</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>.</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;Bid</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;that</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;welcome</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>Which</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;comes</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;to</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;punish</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>[MASK]</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>,</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;and</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;we</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;punish</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;it</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>,</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>[MASK]</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>Seem</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>ing</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;to</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;bear</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>[MASK]</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;light</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>ly</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>.</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;Take</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;me</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;up</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>.</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>[MASK]</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>I</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;have</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;led</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;you</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;oft</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>;</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;carry</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;me</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;now</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>,</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;good</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;friends</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>,</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'><br></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>span.token {font-family: Courier New; font-size: 1.1em; font-weight: 300; padding: 0px; margin-right: 0px; border-color: rgba(0, 0, 0, 0.05); border-style: ridge; border-radius: 0px;}</style><div style='background-color: #FBFBFB; line-height: 175%; padding: 25px; border-radius: 8px; margin-left: 10px; margin-right: 10px; margin-top: 20px; margin-bottom: 20px; overflow-x: auto; white-space: nowrap;'><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;have</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;my</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;thanks</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;for</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;all</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>.</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;Exeunt</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>,</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;hearing</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;ANTONY</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>ACT</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;4</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>|</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>SC</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;1</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>5</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;SCENE</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>X</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>V</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>.</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;Alex</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>andria</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>.</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;A</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;monument</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>Enter</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;CLEOPATRA</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;and</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;her</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;maids</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;aloft</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>,</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;with</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;CH</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>ARMIAN</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;and</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;I</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>R</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>AS</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'><br></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>span.token {font-family: Courier New; font-size: 1.1em; font-weight: 300; padding: 0px; margin-right: 0px; border-color: rgba(0, 0, 0, 0.05); border-style: ridge; border-radius: 0px;}</style><div style='background-color: #FBFBFB; line-height: 175%; padding: 25px; border-radius: 8px; margin-left: 10px; margin-right: 10px; margin-top: 20px; margin-bottom: 20px; overflow-x: auto; white-space: nowrap;'><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;friends</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>,</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;where</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;Cleopatra</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;bid</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>es</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>;</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>'</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>Tis</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;the</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;last</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;service</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;that</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;I</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;shall</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;command</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;you</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>.</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>FIRST</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;GUARD</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>.</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;W</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>oe</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>,</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;woe</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;are</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;we</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>,</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;sir</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>,</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;you</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;may</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;not</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;live</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;to</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;wear</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>All</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;your</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;true</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;followers</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;out</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>.</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>ALL</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>.</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;Most</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;heavy</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;day</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>!</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>ANTONY</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>.</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;Nay</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>,</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;good</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;my</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;fellows</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>,</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;do</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;not</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;please</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;sharp</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;fate</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>To</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;grace</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;it</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;with</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;your</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;sorrows</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>.</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;Bid</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;that</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;welcome</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>Which</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;comes</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;to</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;punish</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;us</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>,</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;and</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;we</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;punish</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;it</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>,</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>Seem</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>ing</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;to</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;bear</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;it</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;light</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>ly</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>.</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;Take</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;me</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;up</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>.</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>I</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;have</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;led</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;you</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;oft</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>;</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>&nbsp;carry</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;me</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;now</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>,</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;good</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;friends</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>,</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'><br></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>span.token {font-family: Courier New; font-size: 1.1em; font-weight: 300; padding: 0px; margin-right: 0px; border-color: rgba(0, 0, 0, 0.05); border-style: ridge; border-radius: 0px;}</style><div style='background-color: #FBFBFB; line-height: 175%; padding: 25px; border-radius: 8px; margin-left: 10px; margin-right: 10px; margin-top: 20px; margin-bottom: 20px; overflow-x: auto; white-space: nowrap;'><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;my</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;thanks</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;for</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;all</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>.</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;Exeunt</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>,</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;hearing</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;ANTONY</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>ACT</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;4</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>|</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>SC</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;1</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>5</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;SCENE</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>X</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>V</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>.</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;Alex</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>andria</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>.</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;A</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;monument</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>Enter</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;CLEOPATRA</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;and</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>&nbsp;her</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>&nbsp;maids</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'>&nbsp;aloft</span><span class='token' style='background-color: rgba(204, 204, 204, 0.4);'>,</span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;with</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;CH</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>ARMIAN</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'><br></span><span class='token' style='background-color: rgba(179, 226, 205, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(253, 205, 172, 0.4);'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class='token' style='background-color: rgba(203, 213, 232, 0.4);'>&nbsp;and</span><span class='token' style='background-color: rgba(244, 202, 228, 0.4);'>&nbsp;I</span><span class='token' style='background-color: rgba(230, 245, 201, 0.4);'>R</span><span class='token' style='background-color: rgba(255, 242, 174, 0.4);'>AS</span><span class='token' style='background-color: rgba(241, 226, 204, 0.4);'><br></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = viz_tool(_inputs[0][0].numpy().tolist(), display_inline=True)\n",
    "_ = viz_tool(_inputs[1][0].numpy().tolist(), display_inline=True)\n",
    "\n",
    "_ = viz_tool(_labels[0][0].numpy().tolist(), display_inline=True)\n",
    "_ = viz_tool(_labels[1][0].numpy().tolist(), display_inline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e31cad0-a7a4-4fc3-b9d6-e4349a6aaca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spearecode.models.cllm_backbone import CLLM\n",
    "\n",
    "\n",
    "\n",
    "model_config = dict(\n",
    "    vocab_size=-1,\n",
    "    context_length=128,\n",
    "    embedding_size=256,\n",
    "    n_heads=-1,\n",
    "    n_layers=-1,\n",
    "    use_bias=True,\n",
    "    ffn_act=\"gelu\",\n",
    "    expansion_factor=6,\n",
    "    dropout_rate=0.3,\n",
    ")\n",
    "\n",
    "# cllm = CLLM(**model_config)\n",
    "# cllm.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
